# Web Crawler MCP

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![License](https://img.shields.io/badge/License-MIT-green)

Un outil de web crawling puissant qui s'int√®gre avec les assistants IA via le protocole MCP (Machine Conversation Protocol). Ce projet permet de crawler des sites web et d'enregistrer leur contenu sous forme de fichiers Markdown structur√©s.

## üìã Fonctionnalit√©s

- Crawling de sites web avec profondeur configurable
- Support des liens internes et externes
- G√©n√©ration de fichiers Markdown structur√©s
- Int√©gration native avec les assistants IA via MCP
- Statistiques d√©taill√©es des r√©sultats de crawl
- Gestion des erreurs et des pages non trouv√©es

## üöÄ Installation

### Pr√©requis

- Python 3.13 ou sup√©rieur
- pip (gestionnaire de packages Python)

### √âtapes d'installation

1. Clonez ce d√©p√¥t :

```bash
git clone laurentvv/crawl4ai-mcp
cd crawl4ai-mcp
```

2. Cr√©ez un environnement virtuel et activez-le :

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/MacOS
python -m venv .venv
source .venv/bin/activate
```

3. Installez les d√©pendances requises :

```bash
pip install -r requirements.txt
```

## üîß Configuration

### Configuration MCP pour les assistants IA

Pour utiliser ce crawler avec des assistants IA comme VScode Cline, configurez votre fichier `cline_mcp_settings.json` :

```json
{
  "mcpServers": {
    "crawl": {
      "command": "CHEMIN\\VERS\\VOTRE\\ENVIRONNEMENT\\.venv\\Scripts\\python.exe",
      "args": [
        "CHEMIN\\VERS\\VOTRE\\PROJET\\crawl_mcp.py"
      ],
      "disabled": false,
      "autoApprove": [],
      "timeout": 600
    }
  }
}
```

Remplacez `CHEMIN\\VERS\\VOTRE\\ENVIRONNEMENT` et `CHEMIN\\VERS\\VOTRE\\PROJET` par les chemins appropri√©s sur votre syst√®me.

#### Exemple concret (Windows)

```json
{
  "mcpServers": {
    "crawl": {
      "command": "C:\\Python\\crawl4ai-mcp\\.venv\\Scripts\\python.exe",
      "args": [
        "D:\\Python\\crawl4ai-mcp\\crawl_mcp.py"
      ],
      "disabled": false,
      "autoApprove": [],
      "timeout": 600
    }
  }
}
```

## üñ•Ô∏è Utilisation

### Utilisation avec un assistant IA (via MCP)

Une fois configur√© dans votre assistant IA, vous pouvez utiliser le crawler en demandant √† l'assistant d'effectuer un crawl avec la syntaxe suivante :

```
Pouvez-vous crawler le site web https://exemple.com avec une profondeur de 2 ?
```

L'assistant utilisera le protocole MCP pour ex√©cuter l'outil de crawling avec les param√®tres sp√©cifi√©s.

### Exemples d'utilisation avec Claude

Voici des exemples de requ√™tes que vous pouvez faire √† Claude apr√®s avoir configur√© l'outil MCP :

- **Crawl simple** : "Peux-tu crawler le site example.com et m'en donner un r√©sum√© ?"
- **Crawl avec options** : "Peux-tu crawler https://example.com avec une profondeur de 3 et en incluant les liens externes ?"
- **Crawl avec sortie personnalis√©e** : "Peux-tu crawler le blog example.com et enregistrer les r√©sultats dans un fichier nomm√© 'analyse_blog.md' ?"

## üìÅ Structure des r√©sultats

Les r√©sultats du crawl sont enregistr√©s dans le dossier `crawl_results` √† la racine du projet. Chaque fichier de r√©sultat est au format Markdown avec la structure suivante :

```markdown
# https://example.com/page

## M√©tadonn√©es
- Profondeur : 1
- Horodatage : 2023-07-01T12:34:56

## Contenu
Contenu extrait de la page...

---
```

## üõ†Ô∏è Param√®tres disponibles

L'outil de crawl accepte les param√®tres suivants :

| Param√®tre | Type | Description | Valeur par d√©faut |
|-----------|------|-------------|-------------------|
| url | string | URL √† crawler (obligatoire) | - |
| max_depth | integer | Profondeur maximale de crawling | 2 |
| include_external | boolean | Inclure les liens externes | false |
| verbose | boolean | Activer les sorties d√©taill√©es | true |
| output_file | string | Chemin du fichier de sortie | g√©n√©r√© automatiquement |

## ü§ù Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† ouvrir une issue ou √† soumettre une pull request.

## üìÑ Licence

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de d√©tails.
